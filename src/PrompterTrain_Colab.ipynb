{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import torch\n",
    "import gdown\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm\n",
    "import statistics\n",
    "import importlib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "def calculate_centroids(image_label: np.ndarray) -> np.ndarray:\n",
    "    width, height = image_label.shape\n",
    "\n",
    "    # Dimensions of each grid cell\n",
    "    grid_size_x = width // 8\n",
    "    grid_size_y = height // 8\n",
    "\n",
    "    # Initialize the result array with -1 and flag 0\n",
    "    result_array = np.full((8, 8, 3), [-1, -1, 0]).astype(np.float32)\n",
    "\n",
    "    # Process each grid cell\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            x_start = j * grid_size_x\n",
    "            y_start = i * grid_size_y\n",
    "            x_end = x_start + grid_size_x\n",
    "            y_end = y_start + grid_size_y\n",
    "\n",
    "            # Extract the cell from the binary mask\n",
    "            cell = image_label[y_start:y_end, x_start:x_end]\n",
    "\n",
    "            # Find pixels belonging to the object in this cell\n",
    "            points = np.column_stack(np.where(cell > 0))\n",
    "\n",
    "            if points.size > 0:\n",
    "                # Calculate the centroid of these points\n",
    "                centroid = np.mean(points, axis=0)\n",
    "                # Adjust centroid to the coordinate in the full image\n",
    "                result_array[i, j] = [centroid[1] + x_start, centroid[0] + y_start, 1]\n",
    "\n",
    "    return result_array\n",
    "\n",
    "class SidewalkPrompter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SidewalkPrompter, self).__init__()\n",
    "        self.resnet = resnet18()\n",
    "        self.resnet.fc = nn.Linear(in_features=512, out_features=192, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = x.view(x.size(0), 8, 8, 3)\n",
    "        x[:, :, :, 2] = self.sigmoid(x[:, :, :, 2])\n",
    "        return x\n",
    "    \n",
    "class LossFn(nn.Module):\n",
    "    \"\"\"\n",
    "    Loss function for SidewalkPrompter\n",
    "    \n",
    "    Details:\n",
    "    - Ground truth is a 8x8x3 tensor with the last dimension being [x, y, flag]\n",
    "    - flag is 1 if there is a centroid in the grid cell, 0 otherwise.\n",
    "    - Loss fn = MSE([x_hat, y_hat], [x, y]) (if flag == 1) + \\lambda BCE(flag_hat, flag)\n",
    "    - \\lambda is a hyperparameter, default value is 5.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LossFn, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction='sum')  # Set reduction to 'sum'\n",
    "        self.bce = nn.BCELoss(reduction='sum')  # Set reduction to 'sum'\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        # Extract x, y, flag from the target tensor\n",
    "        x, y, flag = target[:, :, :, 0], target[:, :, :, 1], target[:, :, :, 2]\n",
    "        \n",
    "        # Extract x_hat, y_hat, flag_hat from the pred tensor\n",
    "        x_hat, y_hat, flag_hat = pred[:, :, :, 0], pred[:, :, :, 1], pred[:, :, :, 2]\n",
    "        \n",
    "        # Calculate MSE loss only for grid cells where flag is 1\n",
    "        mse_loss = self.mse(x_hat * flag, x * flag) + self.mse(y_hat * flag, y * flag)\n",
    "        \n",
    "        # Calculate BCE loss\n",
    "        bce_loss = self.bce(flag_hat, flag)\n",
    "\n",
    "        return mse_loss + 5 * bce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "label_zip_path = '/content/drive/MyDrive/sidewalks/label.tar.gz'\n",
    "train_zip_path = '/content/drive/MyDrive/sidewalks/train.tar.gz'\n",
    "val_zip_path = '/content/drive/MyDrive/sidewalks/val.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip the files\n",
    "data_path = os.path.join('.', 'data')\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(data_path, 'Train')\n",
    "if not os.path.exists(train_path):\n",
    "    pass\n",
    "    !tar -xzf {train_zip_path} -C {data_path}\n",
    "label_path = os.path.join(data_path, 'Label')\n",
    "if not os.path.exists(label_path):\n",
    "    pass\n",
    "    !tar -xzf {label_zip_path} -C {data_path}\n",
    "    !rm -rf {os.path.join(label_path, 'Test2')}\n",
    "val_path = os.path.join(data_path, 'Test')\n",
    "if not os.path.exists(val_path):\n",
    "    pass\n",
    "    !tar -xzf {val_zip_path} -C {data_path}\n",
    "\n",
    "\n",
    "train_label_path = os.path.join(label_path, 'Train')\n",
    "val_label_path = os.path.join(label_path, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files = [f for f in os.listdir(train_path) if (f.endswith('.tif') and np.max(tifffile.imread(os.path.join(train_label_path, f))) > 0)]\n",
    "# val_files = [f for f in os.listdir(val_path) if (f.endswith('.tif') and np.max(tifffile.imread(os.path.join(val_label_path, f))) > 0)]\n",
    "train_files = []\n",
    "train_imgs = []\n",
    "train_centroids = []\n",
    "for f in os.listdir(train_path):\n",
    "    if f.endswith('.tif'):\n",
    "        ground_truth = tifffile.imread(os.path.join(train_label_path, f))\n",
    "        if np.max(ground_truth) > 0:\n",
    "            train_files.append(f)\n",
    "            train_imgs.append(tifffile.imread(os.path.join(train_path, f)))\n",
    "            train_centroids.append(calculate_centroids(ground_truth))\n",
    "train_imgs, train_centroids = np.array(train_imgs), np.array(train_centroids)\n",
    "\n",
    "val_files = []\n",
    "val_imgs = []\n",
    "val_centroids = []\n",
    "for f in os.listdir(val_path):\n",
    "    if f.endswith('.tif'):\n",
    "        ground_truth = tifffile.imread(os.path.join(val_label_path, f))\n",
    "        if np.max(ground_truth) > 0:\n",
    "            val_files.append(f)\n",
    "            val_imgs.append(tifffile.imread(os.path.join(val_path, f)))\n",
    "            val_centroids.append(calculate_centroids(ground_truth))\n",
    "val_imgs, val_centroids = np.array(val_imgs), np.array(val_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')    # DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SidewalkDataset(Dataset):\n",
    "    def __init__(self, data_path: str, label_path: str, files: list, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = train_imgs[idx]\n",
    "        file_name = self.files[idx]\n",
    "        img = np.moveaxis(img, -1, 0)\n",
    "        ground_truth = train_centroids[idx]\n",
    "        return {'image': torch.tensor(img).float(), 'ground_truth': torch.tensor(ground_truth).float(), 'file_name': file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SidewalkDataset(train_path, train_label_path, train_files)\n",
    "val_dataset = SidewalkDataset(val_path, val_label_path, val_files)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SidewalkPrompter().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "loss = LossFn().to(device).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result path to save the model\n",
    "result_path = os.path.join('..', 'models')\n",
    "os.makedirs(result_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    for batch in tqdm(train_loader):\n",
    "        img, ground_truth = batch['image'].to(device), batch['ground_truth'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img)\n",
    "        l = loss(pred, ground_truth)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(l.item())\n",
    "    print(f'Epoch {epoch+1} loss: {statistics.mean(epoch_loss)}')\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(result_path, f'sidewalk_prompter_epoch_{epoch+1:04d}.pt'), map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(result_path, 'sidewalk_prompter.pth'), map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_loss = []\n",
    "for batch in tqdm(val_loader):\n",
    "    with torch.no_grad():\n",
    "        img, ground_truth = batch['image'].to(device), batch['ground_truth'].to(device)\n",
    "        pred = model(img)\n",
    "        l = loss(pred, ground_truth)\n",
    "        val_loss.append(l.item())\n",
    "print(f'Validation loss: {statistics.mean(val_loss)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
